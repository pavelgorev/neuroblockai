{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8019a",
   "metadata": {
    "id": "68d8019a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import random\n",
    "from operator import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f590e",
   "metadata": {
    "id": "a26f590e"
   },
   "outputs": [],
   "source": [
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "# TODO: the parameters of the trained network should be saved into a file.\n",
    "class c_function():\n",
    "    def __init__(self, isBoolean):\n",
    "        self.isBoolean = isBoolean\n",
    "        self.hidden_layer_size = -1\n",
    "    \n",
    "    def __call__(self, trial_code):\n",
    "        return self.network(torch.FloatTensor(trial_code).to(device)).detach().numpy()\n",
    "    \n",
    "    def train(self, raw_train_data):\n",
    "        \n",
    "        if self.hidden_layer_size <= 0:\n",
    "            self.hidden_layer_size = 4\n",
    "        \n",
    "        while True:\n",
    "            print (f'Started training. {self.hidden_layer_size = }')\n",
    "            \n",
    "            train_loss, val_loss = self.try_train(self.hidden_layer_size, raw_train_data)\n",
    "            print(f'{self.hidden_layer_size = } | {train_loss = :.2f} {val_loss = :.2f}')\n",
    "\n",
    "            if (train_loss < 0.5) and (val_loss - train_loss > 0.2):\n",
    "                print ('Please provide more training data')\n",
    "                break                \n",
    "            if train_loss >= 0.4:\n",
    "                self.hidden_layer_size = self.hidden_layer_size + 4\n",
    "                print ('Complexity increased.')\n",
    "                continue\n",
    "            elif (0.1 <= train_loss) and (train_loss < 0.4) and (val_loss < 0.4):  # This condition is under question\n",
    "                self.hidden_layer_size = self.hidden_layer_size + 4\n",
    "                print ('Complexity increased.')\n",
    "                continue\n",
    "            elif (train_loss < 0.1) and (val_loss >= 0.1):\n",
    "                print ('Please provide more training data')\n",
    "                break\n",
    "\n",
    "            elif (train_loss < 0.1) and (val_loss < 0.1):\n",
    "                print ('Ready')\n",
    "                break\n",
    "            else:\n",
    "                raise Exception('Unexpected situation')\n",
    "                \n",
    "    \n",
    "    def try_train(self, hidden_layer_size, raw_train_data, print_intermediate=False):\n",
    "        learning_rate = 0.005\n",
    "        epochs = 1500\n",
    "        \n",
    "        data_inputs = torch.FloatTensor([data_sample[0] for data_sample in raw_train_data]).to(device)\n",
    "        data_outputs = torch.FloatTensor([data_sample[1] for data_sample in raw_train_data]).to(device)\n",
    "        dataset = torch.utils.data.TensorDataset(data_inputs, data_outputs)\n",
    "    \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(data_inputs.size()[-1], hidden_layer_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "#             nn.Linear(hidden_layer_size, hidden_layer_size),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_layer_size, data_outputs.size()[-1])\n",
    "        ).to(device)\n",
    "        if self.isBoolean:\n",
    "            self.network = nn.Sequential(self.network, nn.Sigmoid())\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.network.parameters(), lr=learning_rate)\n",
    "        \n",
    "        \n",
    "        criterion = nn.BCELoss() if self.isBoolean else nn.L1Loss()\n",
    "        \n",
    "        # TODO: need to use cross-validation\n",
    "        train_size = int(0.7 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "    \n",
    "        train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=val_size, shuffle=True)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for n, samples in enumerate(train_loader):\n",
    "\n",
    "                inputs = samples[0]\n",
    "                expected_outputs = samples[1]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                actual_outputs = self.network(inputs)                \n",
    "        \n",
    "                train_loss = criterion(actual_outputs, expected_outputs)\n",
    "                \n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                                \n",
    "            for n, samples in enumerate(val_loader):\n",
    "\n",
    "                inputs = samples[0]\n",
    "                expected_outputs = samples[1]\n",
    "\n",
    "                actual_outputs = self.network(inputs)\n",
    "                val_loss = criterion(actual_outputs, expected_outputs)\n",
    "               \n",
    "            if print_intermediate:\n",
    "                print(f'E {epoch} | {train_loss = :.2f} {val_loss = :.2f}')\n",
    "            \n",
    "        return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94f848",
   "metadata": {
    "id": "0f94f848"
   },
   "outputs": [],
   "source": [
    "# Utility for creation of a training data for errors detection\n",
    "\n",
    "def get_errors_test_data(n):\n",
    "    res = []\n",
    "    for _ in range(n):\n",
    "\n",
    "        code = [random.randint(0, 9) for x in range(4)]\n",
    "        has_errors = 1 if len(code) != len(set(code)) else 0\n",
    "        res.append([code, [has_errors]])\n",
    "        \n",
    "    return res\n",
    "\n",
    "print(get_errors_test_data(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87581a0",
   "metadata": {
    "id": "c87581a0"
   },
   "outputs": [],
   "source": [
    "# Utility for creation of a training data for bulls count\n",
    "\n",
    "def generate_list_without_duplicates(possible_numbers, length):\n",
    "    return random.sample(possible_numbers, length)\n",
    "\n",
    "def get_bulls_test_data(n):\n",
    "    res = []\n",
    "    for _ in range(n):\n",
    "\n",
    "        # I cannot generate secret_code and guessed_code at first, and then calculate the \n",
    "        # bulls count. It's much easier, but it provides a biased data with a lot of \n",
    "        # samples with 0 bulls and very few samples with 3 and 4 bulls.\n",
    "        \n",
    "        secret_code = generate_list_without_duplicates(range(10), 4)\n",
    "        bulls_count = random.randint(0, 4)\n",
    "        \n",
    "        unused_numbers = set(range(10)) - set(secret_code)\n",
    "        \n",
    "        guessed_code = generate_list_without_duplicates(unused_numbers, 4)\n",
    "        \n",
    "#         indices_to_place_bulls_to = generate_list_without_duplicates(range(4), bulls_count)\n",
    "#         bulls = generate_list_without_duplicates(secret_code, bulls_count)\n",
    "        bulls_indices = generate_list_without_duplicates(range(4), bulls_count)\n",
    "                \n",
    "        for bull_index in bulls_indices:\n",
    "            guessed_code[bull_index] = secret_code[bull_index]\n",
    "        \n",
    "        res.append([secret_code + guessed_code, [bulls_count]])\n",
    "        \n",
    "    return res\n",
    "\n",
    "get_bulls_test_data(10)\n",
    "# print(get_bulls_test_data(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c594c",
   "metadata": {
    "id": "e54c594c"
   },
   "outputs": [],
   "source": [
    "# Create dependencies\n",
    "has_errors = c_function(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78de01",
   "metadata": {
    "id": "5e78de01"
   },
   "outputs": [],
   "source": [
    "find_bulls_count = c_function(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6889d5",
   "metadata": {
    "id": "8c6889d5"
   },
   "outputs": [],
   "source": [
    "# Train dependencies\n",
    "has_errors.train(get_errors_test_data(32*160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a558852",
   "metadata": {
    "id": "8a558852"
   },
   "outputs": [],
   "source": [
    "# Train dependencies\n",
    "find_bulls_count.train(get_bulls_test_data(32*40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3314171",
   "metadata": {
    "id": "e3314171"
   },
   "outputs": [],
   "source": [
    "def try_guess(trial_code):    \n",
    "    code_has_errors = has_errors(trial_code)\n",
    "    print(code_has_errors)\n",
    "    \n",
    "    if(round(code_has_errors[0]) == 1):\n",
    "        print('error')\n",
    "    else:\n",
    "        print(f'bulls_count: {round(find_bulls_count(trial_code + g_secretCode)[0])}')\n",
    "        #print(f'{result[1]} bulls; {result[2]} cows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9ca0e",
   "metadata": {
    "id": "9bb9ca0e"
   },
   "outputs": [],
   "source": [
    "g_secretCode = [5, 4, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e98a5f",
   "metadata": {
    "id": "37e98a5f"
   },
   "outputs": [],
   "source": [
    "try_guess(     [2, 5, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0900e",
   "metadata": {
    "id": "9ab0900e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
